import scipy.sparse
from scipy.linalg import toeplitz
import numpy as np
import cv2
from scipy.ndimage import convolve

#===========================================
'''List of Functions:
   get_grad_sobel(img: np.ndarray, x: int):
    return grad of img using sobel api from cv2
    
   gen_grad_kernel(x: int, transpose:int = 0):
    used to generate a standard 3x3 x or y direction gradient filter
    
   gen_doubly_blocked_toeplitz(kernel: np.ndarray, m: int, n: int):
    used to generate a doubly blocked toeplitz matrix for 2d conv operation
    
   get_grad_doubly_blocked_toeplitz(map: np.ndarray, x: int):
    used to generate gradient with the gen_toeplitz function
    
   gen_D(m):, gen_D_truncated(m):
    used to generate a toeplitz matrix for simplified gradient (may be incorrect)

   get_grad_toeplitz(map: np.ndarray, x: int), get_grad_toeplitz_transposed(map: np.ndarray, x: int):
    use matrices generated by gen_D to get gradient, faster than the doubly blocked toeplitz
    
   get_grad_conv(map: np.ndarray, x:int, trans:int, mode:str = 'wrap):
    use a simple convolution operation to get gradient, quite versatile, can choose padding from 'wrap', 'mirror', 'copy' etc.
   '''

def gen_D_large(m:int, n:int, x:int, trans:int):
    num_cols = m * n
    data = [1]
    cols = []
    len_col = m
    len_row = n
    for i in range(num_cols):
        row = [int(i / len_row)]
        col = [i % len_row]
        mat = scipy.sparse.csr_matrix((data, (row, col)), shape=(len_col, len_row))
        right = mat.toarray()
        conv = convolve(right, gen_grad_kernel(x, trans), mode='wrap')
        arr = conv.flatten()
        cols.append(arr.reshape(num_cols, 1))
    print(cols)
    mat = cols[0]
    for i in range(len(cols) - 1):
        mat = np.hstack((mat, cols[i + 1]))
    return mat
#===============================================#
# easy mode with sobel api
def get_grad_sobel(img: np.ndarray, x: int):
    grad_img = cv2.Sobel(img, cv2.CV_64F, int(x == 1), int(x == 0), ksize=1)
    return grad_img

#==================================================================================================================#
# super hard mode with doubly blocked toeplitz (memory overflow warning lol) recommended with images around 100x100
# the gen_grad_kernel function can be used later by an intermediate method

def gen_grad_kernel(x: int, transpose:int = 0):  # x=0 for vertical
    if transpose == 0:
        return np.asarray([[0, int(x == 0), 0], [int(x == 1), -1, 0], [0, 0, 0]])
    if transpose == 1:
        return np.asarray([[0, 0, 0], [0, -1, int(x == 1)], [0, int(x == 0), 0]])


def gen_doubly_blocked_toeplitz(kernel: np.ndarray, m: int, n: int):
    k_m, k_n = kernel.shape
    kernel_padded = np.pad(kernel, ((m - k_m, 0), (0, n - k_n)), 'constant', constant_values=0)
    # print(kernel_padded)
    toeplitz_lst = []
    for i in range(kernel_padded.shape[0] - 1, -1, -1):
        col = kernel_padded[i, :]
        row = np.r_[col[0], np.zeros(n - 1)]
        toeplitz_ = toeplitz(col, row)
        # print(toeplitz_)
        toeplitz_lst.append(toeplitz_)
    toeplitz_shape = list(toeplitz_lst[0].shape)
    c = range(1, kernel_padded.shape[0] + 1)
    r = np.r_[c[0], np.zeros(m - 1, dtype=int)]
    doubly_indices = toeplitz(c, r)
    # print(doubly_indices)
    h = toeplitz_shape[0] * doubly_indices.shape[0]
    w = toeplitz_shape[1] * doubly_indices.shape[1]
    doubly_blocked_toeplitz = np.zeros((h, w))
    for i in range(doubly_indices.shape[0]):
        for j in range(doubly_indices.shape[1]):
            start_i = i * toeplitz_shape[0]
            start_j = j * toeplitz_shape[1]
            end_i = start_i + toeplitz_shape[0]
            end_j = start_j + toeplitz_shape[1]
            doubly_blocked_toeplitz[start_i:end_i, start_j:end_j] = toeplitz_lst[doubly_indices[i, j] - 1]
    # print(doubly_blocked_toeplitz)
    return doubly_blocked_toeplitz


def get_grad_doubly_blocked_toeplitz(map: np.ndarray, x: int):
    if x == 0 or x == 1:
        m, n = map.shape
        toeplitz_D = gen_doubly_blocked_toeplitz(gen_grad_kernel(int(x == 1)), m, n)
        in_vec = map.flatten()
        out_vec = np.dot(toeplitz_D, in_vec)
        output = out_vec.reshape((m, n))
        return output
    if x == 2:
        m, n = map.shape
        toeplitz_D_x = gen_doubly_blocked_toeplitz(gen_grad_kernel(0), m, n)
        toeplitz_D_y = gen_doubly_blocked_toeplitz(gen_grad_kernel(1), m, n)
        print(toeplitz_D_x)
        print(toeplitz_D_y)
        in_vec = map.flatten()
        out_vec_x = np.dot(toeplitz_D_x, in_vec)
        output_x = out_vec_x.reshape((m, n))
        out_vec_y = np.dot(toeplitz_D_y, in_vec)
        output_y = out_vec_y.reshape((m, n))
        return np.vstack((output_x, output_y))

#======================================================================
# relatively easy mode with a simplified version of the toeplitz matrix

def gen_D(m):
    D = np.zeros((m, m + 1))
    for i in range(m):
        D[i,i] = -1
        D[i, i+1] = 1
    return D

def gen_D_truncated(m):
    D = np.zeros((m, m))
    for i in range(m):
        D[i,i] = -1
        if i+1 < m:
            D[i, i+1] = 1
    return D

def get_grad_toeplitz(map: np.ndarray, x: int):
    m, n = map.shape
    if x == 0:  # vertical
        extended = np.zeros((m + 1, n))
        extended[0:m, 0:n] = map
        extended[m, 0:n] = map[0, 0:n]
        D = gen_D(m)
        return np.dot(D, extended)
    if x == 1:  # horizontal
        extended = np.zeros((m, n + 1))
        extended[0:m, 0:n] = map
        extended[0:m, n] = map[0:m, 0]
        D = gen_D(n).T
        return np.dot(extended, D)
    if x == 2:  # concact both vertically
        extended_v = np.zeros((m + 1, n))
        extended_v[0:m, 0:n] = map
        extended_v[m, 0:n] = map[0, 0:n]
        D_v = gen_D(m)
        grad_v = np.dot(D_v, extended_v)

        extended_h = np.zeros((m, n + 1))
        extended_h[0:m, 0:n] = map
        extended_h[0:m, n] = map[0:m, 0]
        D_h = gen_D(n).T
        grad_h = np.dot(extended_h, D_h)
        return np.vstack((grad_h, grad_v))
    # an attempt to process both h and v at the same time but complexities arise when trying to combine W_h and W_v
    if x == 3:  # return magnitude
        extended_v = np.zeros((m + 1, n))
        extended_v[0:m, 0:n] = map
        extended_v[m, 0:n] = map[0, 0:n]
        D_v = gen_D(m)
        grad_v = np.dot(D_v, extended_v)

        extended_h = np.zeros((m, n + 1))
        extended_h[0:m, 0:n] = map
        extended_h[0:m, n] = map[0:m, 0]
        D_h = gen_D(n).T
        grad_h = np.dot(extended_h, D_h)
        return np.sqrt(np.add(np.square(grad_h), np.square(grad_v)))


def get_grad_toeplitz_transpose(map: np.ndarray, x: int):
    m, n = map.shape
    if x == 0:  # vertical
        extended_v = np.zeros((m, n))
        extended_v[0:m, 0:n] = map
        D = gen_D(m).T
        D_truncated = D[0:m, 0:m]
        return np.dot(D_truncated, extended_v)
    if x == 1:  # horizontal
        extended_h = np.zeros((m, n + 1))
        extended_h[0:m, 0:n] = map
        extended_h[0:m, n] = map[0:m, 0]
        D = gen_D(n).T
        return np.dot(extended_h, D)

#=========================================================
# random function for generating magnitudes, mostly unused
def get_magnitude(a: np.ndarray, b: np.ndarray):
    return np.sqrt(np.square(a) + np.square(b))

#================================================================
# relatively easy method using convolution, with circular padding
def get_grad_conv(map: np.ndarray, x:int, trans:int = 0, mode:str = 'wrap'):
    if trans == 0:
        if x == 0 or x == 1:
            grad = convolve(map, gen_grad_kernel(x), mode=mode)
            return grad

        if x == 2:
            grad_v = convolve(map, gen_grad_kernel(0), mode=mode)
            grad_h = convolve(map, gen_grad_kernel(1), mode=mode)
            grad = np.vstack((grad_h, grad_v))
            return grad
    if trans == 1:
        if x == 0 or x == 1:
            grad = convolve(map, gen_grad_kernel(x, trans), mode=mode)
            return grad

        if x == 2:
            grad_v = convolve(map, gen_grad_kernel(0, trans), mode=mode)
            grad_h = convolve(map, gen_grad_kernel(1, trans), mode=mode)
            grad = np.vstack((grad_h, grad_v))
            return grad

def gen_D_conv(m:int, x:int, trans:int = 0, mode:str = 'wrap'):
    '''consider the formula DX = conv(d, X), D should be invariant to the choice of X
       therefore we can simply choose X to be eye(m) or eye(n) for the normal case and the transposed case respectively'''
    if x == 0:
        if trans == 0:
            I = np.eye(m)
            D_v = convolve(I, gen_grad_kernel(0, trans), mode=mode)
            return D_v
        if trans == 1:
            I = np.eye(m)
            D_v = convolve(I, gen_grad_kernel(0, trans), mode=mode)
            return D_v
    if x == 1:
        if trans == 0:
            I = np.eye(m)
            D_h = convolve(I, gen_grad_kernel(1, trans), mode=mode)
            return D_h
        if trans == 1:
            I = np.eye(m)
            D_h = convolve(I, gen_grad_kernel(1, trans), mode=mode)
            return D_h
    if x == 2:
        if trans == 0:
            I = np.eye(m)
            D_v = convolve(I, gen_grad_kernel(0, trans), mode=mode)
            D_h = convolve(I, gen_grad_kernel(1, trans), mode=mode)
            return np.vstack((D_h, D_v))
        if trans == 1:
            I = np.eye(m)
            D_v = convolve(I, gen_grad_kernel(0, trans), mode=mode)
            D_h = convolve(I, gen_grad_kernel(1, trans), mode=mode)
            return np.vstack((D_h, D_v))
if __name__ == '__main__':
    m, n = 3, 2
    Dy = gen_D_large(m, n, 0, 0)
    Dx = gen_D_large(m, n, 1, 0)
    Dy_T = gen_D_large(m, n, 0, 1)
    Dx_T = gen_D_large(m, n, 1, 1)
    print(np.vstack((np.ones((2,3)), np.zeros((2,3)))))

    print(Dy)
    print(Dx)
    print(Dy_T)
    print(Dx_T)